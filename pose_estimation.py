# -*- coding: utf-8 -*-
"""pose_estimation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/samedit66/keras-human-pose/blob/master/pose_estimation.ipynb
"""

# import all the necessary modules
# @author : zabir-nabil
import keras
from keras.models import Sequential
from keras.models import Model
from keras.layers import Input, Dense, Activation, Lambda
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import BatchNormalization
from keras.layers import Concatenate
import scipy
import math

# import the pose estimation model and processing module
from PoseEstimationModel import *
from PoseEstimationProcessing import *

# load the pre-trained weights
pe = PoseEstimationModel('model.h5')
# download the pre-trained weights
# https://drive.google.com/file/d/1n-H_cvTHNldZuz08EE62WiVtqqXzemKq/view?usp=sharing
pemodel = pe.create_model() # create the model
pemodel.summary()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import cv2
import matplotlib
import pylab as plt
import numpy as np
# load a test image
test_image = 'test.jpg'

# credit: https://image.freepik.com/free-photo/couple-dance-pose-holding-hands_23-2147711535.jpg

oriImg = cv2.imread(test_image) # B,G,R order
print(oriImg.shape)
plt.imshow(oriImg[:,:,[2,1,0]])

processor = PoseEstimationProcessing() # load the processor
shared_pts = processor.shared_points(pemodel, oriImg) # shared points across multiple subjects

shared_pts

from PlotPoints import *

plot_circles(oriImg, shared_pts)

plot_body_parts(test_image, shared_pts)

subject_wise_loc = processor.subject_points(shared_pts)

subject_wise_loc = np.array(subject_wise_loc)

subject_wise_loc.shape # body parts, subject, X, Y

subject_wise_loc

colors = [[255, 0, 0], [255, 85, 0], [255, 170, 0], [255, 255, 0], [170, 255, 0], [85, 255, 0], [0, 255, 0], \
          [0, 255, 85], [0, 255, 170], [0, 255, 255], [0, 170, 255], [0, 85, 255], [0, 0, 255], [85, 0, 255], \
          [170, 0, 255], [255, 0, 255], [255, 0, 170], [255, 0, 85]]

cmap = matplotlib.cm.get_cmap('hsv')

canvas = cv2.imread(test_image)
stickwidth = 4

for i in range(len(subject_wise_loc)):

    for n in range(len(subject_wise_loc[i])):

        cur_canvas = canvas.copy()
        Y = subject_wise_loc[i][n][1]
        X = subject_wise_loc[i][n][0]

        mX = np.mean(X)
        mY = np.mean(Y)

        length = ((X[0] - X[1]) ** 2 + (Y[0] - Y[1]) ** 2) ** 0.5
        angle = math.degrees(math.atan2(X[0] - X[1], Y[0] - Y[1]))
        polygon = cv2.ellipse2Poly((int(mY),int(mX)), (int(length/2), stickwidth), int(angle), 0, 360, 1)
        cv2.circle(canvas, (int(mY),int(mX)), 10, colors[i], thickness=-1)

        cv2.fillConvexPoly(cur_canvas, polygon, colors[i])
        canvas = cv2.addWeighted(canvas, 0.4, cur_canvas, 0.6, 0)


plt.imshow(canvas[:,:,[2,1,0]])
fig = matplotlib.pyplot.gcf()
fig.set_size_inches(12, 12)

cv2.imwrite('out.png', canvas)